apiVersion: cluster.x-k8s.io/v1alpha3
kind: Cluster
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: {{.clusterName}}
  name: {{.clusterName}}
  namespace: {{.eksaSystemNamespace}}
spec:
  clusterNetwork:
    pods:
      cidrBlocks: {{.podCidrs}}
    services:
      cidrBlocks: {{.serviceCidrs}}
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
    kind: KubeadmControlPlane
    name: {{.clusterName}}
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: VSphereCluster
    name: {{.clusterName}}
{{- if .externalEtcd }}
  managedExternalEtcdRef:
    apiVersion: etcdcluster.cluster.x-k8s.io/v1alpha3
    kind: EtcdadmCluster
    name: {{.clusterName}}-etcd
{{- end }}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: VSphereCluster
metadata:
  name: {{.clusterName}}
  namespace: {{.eksaSystemNamespace}}
spec:
  cloudProviderConfiguration:
    global:
      secretName: cloud-provider-vsphere-credentials
      secretNamespace: kube-system
      thumbprint: '{{.thumbprint}}'
      insecure: {{.insecure}}
    network:
      name: {{.vsphereNetwork}}
    providerConfig:
      cloud:
        controllerImage: {{.managerImage}}
    virtualCenter:
      {{.vsphereServer}}:
        datacenters: {{.vsphereDatacenter}}
        thumbprint: '{{.thumbprint}}'
    workspace:
      datacenter: {{.vsphereDatacenter}}
      datastore: {{.controlPlaneVsphereDatastore}}
      folder: '{{.controlPlaneVsphereFolder}}'
      resourcePool: '{{.controlPlaneVsphereResourcePool}}'
      server: {{.vsphereServer}}
  controlPlaneEndpoint:
    host: {{.controlPlaneEndpointIp}}
    port: 6443
  server: {{.vsphereServer}}
  thumbprint: '{{.thumbprint}}'
---
{{- if .needsNewControlPlaneTemplate }}
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: VSphereMachineTemplate
metadata:
  name: {{.controlPlaneTemplateName}}
  namespace: {{.eksaSystemNamespace}}
spec:
  template:
    spec:
      cloneMode: linkedClone
      datacenter: {{.vsphereDatacenter}}
      datastore: {{.controlPlaneVsphereDatastore}}
      diskGiB: {{.controlPlaneDiskGiB}}
      folder: '{{.controlPlaneVsphereFolder}}'
      memoryMiB: {{.controlPlaneVMsMemoryMiB}}
      network:
        devices:
        - dhcp4: true
          networkName: {{.vsphereNetwork}}
      numCPUs: {{.controlPlaneVMsNumCPUs}}
      resourcePool: '{{.controlPlaneVsphereResourcePool}}'
      server: {{.vsphereServer}}
{{- if (ne .controlPlaneVsphereStoragePolicyName "") }}
      storagePolicyName: "{{.controlPlaneVsphereStoragePolicyName}}"
{{- end }}
      template: {{.vsphereTemplate}}
      thumbprint: '{{.thumbprint}}'
{{- end }}
---
{{- if .needsNewWorkloadTemplate }}
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: VSphereMachineTemplate
metadata:
  name: {{.workloadTemplateName}}
  namespace: {{.eksaSystemNamespace}}
spec:
  template:
    spec:
      cloneMode: linkedClone
      datacenter: {{.vsphereDatacenter}}
      datastore: {{.workerVsphereDatastore}}
      diskGiB: {{.workloadDiskGiB}}
      folder: '{{.workerVsphereFolder}}'
      memoryMiB: {{.workloadVMsMemoryMiB}}
      network:
        devices:
        - dhcp4: true
          networkName: {{.vsphereNetwork}}
      numCPUs: {{.workloadVMsNumCPUs}}
      resourcePool: '{{.workerVsphereResourcePool}}'
      server: {{.vsphereServer}}
{{- if (ne .workerVsphereStoragePolicyName "") }}
      storagePolicyName: "{{.workerVsphereStoragePolicyName}}"
{{- end }}
      template: {{.vsphereTemplate}}
      thumbprint: '{{.thumbprint}}'
{{- end }}
---
apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
kind: KubeadmControlPlane
metadata:
  name: {{.clusterName}}
  namespace: {{.eksaSystemNamespace}}
spec:
  infrastructureTemplate:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: VSphereMachineTemplate
    name: {{.controlPlaneTemplateName}}
  kubeadmConfigSpec:
    clusterConfiguration:
      imageRepository: {{.kubernetesRepository}}
      etcd:
{{- if .externalEtcd }}
        external:
          endpoints: []
{{- if (eq .format "bottlerocket") }}
          caFile: "/var/lib/kubeadm/pki/etcd/ca.crt"
          certFile: "/var/lib/kubeadm/pki/server-etcd-client.crt"
          keyFile: "/var/lib/kubeadm/pki/apiserver-etcd-client.key"
{{- else }}
          caFile: "/etc/kubernetes/pki/etcd/ca.crt"
          certFile: "/etc/kubernetes/pki/apiserver-etcd-client.crt"
          keyFile: "/etc/kubernetes/pki/apiserver-etcd-client.key"
{{- end }}
{{- else }}
        local:
          imageRepository: {{.etcdRepository}}
          imageTag: {{.etcdImageTag}}
{{- end }}
      dns:
        type: CoreDNS
        imageRepository: {{.corednsRepository}}
        imageTag: {{.corednsVersion}}
{{- if (eq .format "bottlerocket") }}
      pause:
        imageRepository: {{.pauseRepository}}
        imageTag: {{.pauseVersion}}
      bottlerocketBootstrap:
        imageRepository: {{.bottlerocketBootstrapRepository}}
        imageTag: {{.bottlerocketBootstrapVersion}}
{{- end }}
{{- if and .proxyConfig (eq .format "bottlerocket")}}
        proxy:
          httpsProxy: {{.httpsProxy}}
          noProxy: {{ range .noProxy }}
            - {{ . }}
          {{- end }}
{{- end }}
      apiServer:
        extraArgs:
          cloud-provider: external
{{- if .extraArgs }}
{{ .extraArgs.ToYaml | indent 10 }}
{{- end }}
      controllerManager:
        extraArgs:
          cloud-provider: external
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          creationTimestamp: null
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
          - args:
            - start
            env:
            - name: vip_arp
              value: "true"
            - name: vip_leaderelection
              value: "true"
            - name: vip_address
              value: {{.controlPlaneEndpointIp}}
            - name: vip_interface
              value: eth0
            - name: vip_leaseduration
              value: "15"
            - name: vip_renewdeadline
              value: "10"
            - name: vip_retryperiod
              value: "2"
            image: {{.kubeVipImage}}
            imagePullPolicy: IfNotPresent
            name: kube-vip
            resources: {}
            securityContext:
              capabilities:
                add:
                - NET_ADMIN
                - SYS_TIME
            volumeMounts:
            - mountPath: /etc/kubernetes/admin.conf
              name: kubeconfig
          hostNetwork: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/admin.conf
              type: FileOrCreate
            name: kubeconfig
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
{{- if and .proxyConfig (ne .format "bottlerocket")}}
    - content: |
        [Service]
        Environment="HTTP_PROXY={{.httpProxy}}"
        Environment="HTTPS_PROXY={{.httpsProxy}}"
        Environment="NO_PROXY={{ stringsJoin .noProxy "," }}"
      owner: root:root
      path: /etc/systemd/system/containerd.service.d/http-proxy.conf
{{- end }}
    initConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{`{{ ds.meta_data.hostname }}`}}'
    joinConfiguration:
{{- if (eq .format "bottlerocket") }}
      pause:
        imageRepository: {{.pauseRepository}}
        imageTag: {{.pauseVersion}}
      bottlerocketBootstrap:
        imageRepository: {{.bottlerocketBootstrapRepository}}
        imageTag: {{.bottlerocketBootstrapVersion}}
{{- end }}
{{- if and .proxyConfig (eq .format "bottlerocket")}}
      proxy:
        httpsProxy: {{.httpsProxy}}
        noProxy: {{ range .noProxy }}
        - {{ . }}
        {{- end }}
{{- end }}
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{`{{ ds.meta_data.hostname }}`}}'
    preKubeadmCommands:
{{- if and .proxyConfig (ne .format "bottlerocket")}}
    - sudo systemctl daemon-reload
    - sudo systemctl restart containerd
{{- end }}
    - hostname "{{`{{ ds.meta_data.hostname }}`}}"
    - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
    - echo "127.0.0.1   localhost" >>/etc/hosts
    - echo "127.0.0.1   {{`{{ ds.meta_data.hostname }}`}}" >>/etc/hosts
    - echo "{{`{{ ds.meta_data.hostname }}`}}" >/etc/hostname
    useExperimentalRetryJoin: true
    users:
    - name: {{.controlPlaneSshUsername}}
      sshAuthorizedKeys:
      - '{{.vsphereControlPlaneSshAuthorizedKey}}'
      sudo: ALL=(ALL) NOPASSWD:ALL
    format: {{.format}}
  replicas: {{.controlPlaneReplicas}}
  version: {{.kubernetesVersion}}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: {{.clusterName}}-md-0
  namespace: {{.eksaSystemNamespace}}
spec:
  template:
    spec:
      joinConfiguration:
{{- if (eq .format "bottlerocket") }}
        pause:
          imageRepository: {{.pauseRepository}}
          imageTag: {{.pauseVersion}}
        bottlerocketBootstrap:
          imageRepository: {{.bottlerocketBootstrapRepository}}
          imageTag: {{.bottlerocketBootstrapVersion}}
{{- end }}
{{- if and .proxyConfig (eq .format "bottlerocket")}}
        proxy:
          httpsProxy: {{.httpsProxy}}
          noProxy: {{ range .noProxy }}
            - {{ . }}
          {{- end }}
{{- end }}
        nodeRegistration:
          criSocket: /var/run/containerd/containerd.sock
          kubeletExtraArgs:
            cloud-provider: external
          name: '{{"{{"}} ds.meta_data.hostname {{"}}"}}'
{{- if and .proxyConfig (ne .format "bottlerocket")}}
      files:
      - content: |
          [Service]
          Environment="HTTP_PROXY={{.httpProxy}}"
          Environment="HTTPS_PROXY={{.httpsProxy}}"
          Environment="NO_PROXY={{ stringsJoin .noProxy "," }}"
        owner: root:root
        path: /etc/systemd/system/containerd.service.d/http-proxy.conf
{{- end }}
      preKubeadmCommands:
{{- if and .proxyConfig (ne .format "bottlerocket")}}
      - sudo systemctl daemon-reload
      - sudo systemctl restart containerd
{{- end }}
      - hostname "{{`{{ ds.meta_data.hostname }}`}}"
      - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
      - echo "127.0.0.1   localhost" >>/etc/hosts
      - echo "127.0.0.1   {{`{{ ds.meta_data.hostname }}`}}" >>/etc/hosts
      - echo "{{`{{ ds.meta_data.hostname }}`}}" >/etc/hostname
      users:
      - name: {{.workerSshUsername}}
        sshAuthorizedKeys:
        - '{{.vsphereWorkerSshAuthorizedKey}}'
        sudo: ALL=(ALL) NOPASSWD:ALL
      format: {{.format}}
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: {{.clusterName}}
  name: {{.clusterName}}-md-0
  namespace: {{.eksaSystemNamespace}}
spec:
  clusterName: {{.clusterName}}
  replicas: {{.workerReplicas}}
  selector:
    matchLabels: {}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: {{.clusterName}}
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
          name: {{.clusterName}}-md-0
      clusterName: {{.clusterName}}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: VSphereMachineTemplate
        name: {{.workloadTemplateName}}
      version: {{.kubernetesVersion}}
---
apiVersion: addons.cluster.x-k8s.io/v1alpha3
kind: ClusterResourceSet
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: {{.clusterName}}
  name: {{.clusterName}}-crs-0
  namespace: {{.eksaSystemNamespace}}
spec:
  clusterSelector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: {{.clusterName}}
  resources:
  - kind: Secret
    name: vsphere-csi-controller
  - kind: ConfigMap
    name: vsphere-csi-controller-role
  - kind: ConfigMap
    name: vsphere-csi-controller-binding
  - kind: Secret
    name: csi-vsphere-config
  - kind: ConfigMap
    name: csi.vsphere.vmware.com
  - kind: ConfigMap
    name: vsphere-csi-node
  - kind: ConfigMap
    name: vsphere-csi-controller
---
{{- if .externalEtcd }}
kind: EtcdadmCluster
apiVersion: etcdcluster.cluster.x-k8s.io/v1alpha3
metadata:
  name: {{.clusterName}}-etcd
  namespace: {{.eksaSystemNamespace}}
spec:
  replicas: {{.externalEtcdReplicas}}
  etcdadmConfigSpec:
    etcdadmBuiltin: true
    format: {{.format}}
{{- if (eq .format "bottlerocket") }}
    bottlerocketConfig:
      etcdImage: {{.etcdImage}}
      bootstrapImage: {{.bottlerocketBootstrapRepository}}:{{.bottlerocketBootstrapVersion}}
      pauseImage: {{.pauseRepository}}:{{.pauseVersion}}
{{- else}}
    cloudInitConfig:
      version: {{.externalEtcdVersion}}
      installDir: "/usr/bin"
    preEtcdadmCommands:
      - hostname "{{`{{ ds.meta_data.hostname }}`}}"
      - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
      - echo "127.0.0.1   localhost" >>/etc/hosts
      - echo "127.0.0.1   {{`{{ ds.meta_data.hostname }}`}}" >>/etc/hosts
      - echo "{{`{{ ds.meta_data.hostname }}`}}" >/etc/hostname
{{- end }}
    users:
      - name: {{.etcdSshUsername}}
        sshAuthorizedKeys:
          - '{{.vsphereEtcdSshAuthorizedKey}}'
        sudo: ALL=(ALL) NOPASSWD:ALL
  infrastructureTemplate:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: VSphereMachineTemplate
    name: {{.etcdTemplateName}}
---
{{- if .needsNewEtcdTemplate }}
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: VSphereMachineTemplate
metadata:
  name: {{.etcdTemplateName}}
  namespace: '{{.eksaSystemNamespace}}'
spec:
  template:
    spec:
      cloneMode: linkedClone
      datacenter: {{.vsphereDatacenter}}
      datastore: {{.etcdVsphereDatastore}}
      diskGiB: {{.etcdDiskGiB}}
      folder: '{{.etcdVsphereFolder}}'
      memoryMiB: {{.etcdVMsMemoryMiB}}
      network:
        devices:
          - dhcp4: true
            networkName: {{.vsphereNetwork}}
      numCPUs: {{.etcdVMsNumCPUs}}
      resourcePool: '{{.etcdVsphereResourcePool}}'
      server: {{.vsphereServer}}
{{- if (ne .etcdVsphereStoragePolicyName "") }}
      storagePolicyName: "{{.etcdVsphereStoragePolicyName}}"
{{- end }}
      template: {{.vsphereTemplate}}
      thumbprint: '{{.thumbprint}}'
---
{{- end }}
{{- end }}
apiVersion: v1
kind: Secret
metadata:
  name: vsphere-csi-controller
  namespace: {{.eksaSystemNamespace}}
stringData:
  data: |
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: vsphere-csi-controller
      namespace: kube-system
type: addons.cluster.x-k8s.io/resource-set
---
apiVersion: v1
data:
  data: |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: vsphere-csi-controller-role
    rules:
    - apiGroups:
      - storage.k8s.io
      resources:
      - csidrivers
      verbs:
      - create
      - delete
    - apiGroups:
      - ""
      resources:
      - nodes
      - pods
      - secrets
      - configmaps
      verbs:
      - get
      - list
      - watch
    - apiGroups:
      - ""
      resources:
      - persistentvolumes
      verbs:
      - get
      - list
      - watch
      - update
      - create
      - delete
      - patch
    - apiGroups:
      - storage.k8s.io
      resources:
      - volumeattachments
      verbs:
      - get
      - list
      - watch
      - update
      - patch
    - apiGroups:
      - storage.k8s.io
      resources:
      - volumeattachments/status
      verbs:
      - patch
    - apiGroups:
      - ""
      resources:
      - persistentvolumeclaims
      verbs:
      - get
      - list
      - watch
      - update
    - apiGroups:
      - storage.k8s.io
      resources:
      - storageclasses
      - csinodes
      verbs:
      - get
      - list
      - watch
    - apiGroups:
      - ""
      resources:
      - events
      verbs:
      - list
      - watch
      - create
      - update
      - patch
    - apiGroups:
      - coordination.k8s.io
      resources:
      - leases
      verbs:
      - get
      - watch
      - list
      - delete
      - update
      - create
    - apiGroups:
      - snapshot.storage.k8s.io
      resources:
      - volumesnapshots
      verbs:
      - get
      - list
    - apiGroups:
      - snapshot.storage.k8s.io
      resources:
      - volumesnapshotcontents
      verbs:
      - get
      - list
kind: ConfigMap
metadata:
  name: vsphere-csi-controller-role
  namespace: {{.eksaSystemNamespace}}
---
apiVersion: v1
data:
  data: |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: vsphere-csi-controller-binding
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: vsphere-csi-controller-role
    subjects:
    - kind: ServiceAccount
      name: vsphere-csi-controller
      namespace: kube-system
kind: ConfigMap
metadata:
  name: vsphere-csi-controller-binding
  namespace: {{.eksaSystemNamespace}}
---
apiVersion: v1
data:
  data: |
    apiVersion: storage.k8s.io/v1
    kind: CSIDriver
    metadata:
      name: csi.vsphere.vmware.com
    spec:
      attachRequired: true
kind: ConfigMap
metadata:
  name: csi.vsphere.vmware.com
  namespace: {{.eksaSystemNamespace}}
---
apiVersion: v1
data:
  data: |
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: vsphere-csi-node
      namespace: kube-system
    spec:
      selector:
        matchLabels:
          app: vsphere-csi-node
      template:
        metadata:
          labels:
            app: vsphere-csi-node
            role: vsphere-csi
        spec:
          containers:
          - args:
            - --v=5
            - --csi-address=$(ADDRESS)
            - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)
            env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: DRIVER_REG_SOCK_PATH
              value: /var/lib/kubelet/plugins/csi.vsphere.vmware.com/csi.sock
            image: {{.nodeDriverRegistrarImage}}
            lifecycle:
              preStop:
                exec:
                  command:
                  - /bin/sh
                  - -c
                  - rm -rf /registration/csi.vsphere.vmware.com-reg.sock /csi/csi.sock
            name: node-driver-registrar
            resources: {}
            securityContext:
              privileged: true
            volumeMounts:
            - mountPath: /csi
              name: plugin-dir
            - mountPath: /registration
              name: registration-dir
          - env:
            - name: CSI_ENDPOINT
              value: unix:///csi/csi.sock
            - name: X_CSI_MODE
              value: node
            - name: X_CSI_SPEC_REQ_VALIDATION
              value: "false"
            - name: VSPHERE_CSI_CONFIG
              value: /etc/cloud/csi-vsphere.conf
            - name: LOGGER_LEVEL
              value: PRODUCTION
            - name: X_CSI_LOG_LEVEL
              value: INFO
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            image: {{.driverImage}}
            livenessProbe:
              failureThreshold: 3
              httpGet:
                path: /healthz
                port: healthz
              initialDelaySeconds: 10
              periodSeconds: 5
              timeoutSeconds: 3
            name: vsphere-csi-node
            ports:
            - containerPort: 9808
              name: healthz
              protocol: TCP
            resources: {}
            securityContext:
              allowPrivilegeEscalation: true
              capabilities:
                add:
                - SYS_ADMIN
              privileged: true
            volumeMounts:
            - mountPath: /etc/cloud
              name: vsphere-config-volume
            - mountPath: /csi
              name: plugin-dir
            - mountPath: /var/lib/kubelet
              mountPropagation: Bidirectional
              name: pods-mount-dir
            - mountPath: /dev
              name: device-dir
          - args:
            - --csi-address=/csi/csi.sock
            image: {{.livenessProbeImage}}
            name: liveness-probe
            resources: {}
            volumeMounts:
            - mountPath: /csi
              name: plugin-dir
          dnsPolicy: Default
          tolerations:
          - effect: NoSchedule
            operator: Exists
          - effect: NoExecute
            operator: Exists
          volumes:
          - name: vsphere-config-volume
            secret:
              secretName: csi-vsphere-config
          - hostPath:
              path: /var/lib/kubelet/plugins_registry
              type: Directory
            name: registration-dir
          - hostPath:
              path: /var/lib/kubelet/plugins/csi.vsphere.vmware.com/
              type: DirectoryOrCreate
            name: plugin-dir
          - hostPath:
              path: /var/lib/kubelet
              type: Directory
            name: pods-mount-dir
          - hostPath:
              path: /dev
            name: device-dir
      updateStrategy:
        type: RollingUpdate
kind: ConfigMap
metadata:
  name: vsphere-csi-node
  namespace: {{.eksaSystemNamespace}}
---
apiVersion: v1
data:
  data: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: vsphere-csi-controller
      namespace: kube-system
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: vsphere-csi-controller
      template:
        metadata:
          labels:
            app: vsphere-csi-controller
            role: vsphere-csi
        spec:
          containers:
          - args:
            - --v=4
            - --timeout=300s
            - --csi-address=$(ADDRESS)
            - --leader-election
            env:
            - name: ADDRESS
              value: /csi/csi.sock
            image: {{.externalAttacherImage}}
            name: csi-attacher
            resources: {}
            volumeMounts:
            - mountPath: /csi
              name: socket-dir
          - env:
            - name: CSI_ENDPOINT
              value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock
            - name: X_CSI_MODE
              value: controller
            - name: VSPHERE_CSI_CONFIG
              value: /etc/cloud/csi-vsphere.conf
            - name: LOGGER_LEVEL
              value: PRODUCTION
            - name: X_CSI_LOG_LEVEL
              value: INFO
            image: {{.driverImage}}
            livenessProbe:
              failureThreshold: 3
              httpGet:
                path: /healthz
                port: healthz
              initialDelaySeconds: 10
              periodSeconds: 5
              timeoutSeconds: 3
            name: vsphere-csi-controller
            ports:
            - containerPort: 9808
              name: healthz
              protocol: TCP
            resources: {}
            volumeMounts:
            - mountPath: /etc/cloud
              name: vsphere-config-volume
              readOnly: true
            - mountPath: /var/lib/csi/sockets/pluginproxy/
              name: socket-dir
          - args:
            - --csi-address=$(ADDRESS)
            env:
            - name: ADDRESS
              value: /var/lib/csi/sockets/pluginproxy/csi.sock
            image: {{.livenessProbeImage}}
            name: liveness-probe
            resources: {}
            volumeMounts:
            - mountPath: /var/lib/csi/sockets/pluginproxy/
              name: socket-dir
          - args:
            - --leader-election
            env:
            - name: X_CSI_FULL_SYNC_INTERVAL_MINUTES
              value: "30"
            - name: LOGGER_LEVEL
              value: PRODUCTION
            - name: VSPHERE_CSI_CONFIG
              value: /etc/cloud/csi-vsphere.conf
            image: {{.syncerImage}}
            name: vsphere-syncer
            resources: {}
            volumeMounts:
            - mountPath: /etc/cloud
              name: vsphere-config-volume
              readOnly: true
          - args:
            - --v=4
            - --timeout=300s
            - --csi-address=$(ADDRESS)
            - --leader-election
            - --default-fstype=ext4
            env:
            - name: ADDRESS
              value: /csi/csi.sock
            image: {{.externalProvisionerImage}}
            name: csi-provisioner
            resources: {}
            volumeMounts:
            - mountPath: /csi
              name: socket-dir
          dnsPolicy: Default
          serviceAccountName: vsphere-csi-controller
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/master
            operator: Exists
          volumes:
          - name: vsphere-config-volume
            secret:
              secretName: csi-vsphere-config
          - emptyDir: {}
            name: socket-dir
kind: ConfigMap
metadata:
  name: vsphere-csi-controller
  namespace: {{.eksaSystemNamespace}}
---
apiVersion: v1
data:
  data: |
    apiVersion: v1
    data:
      csi-migration: "false"
    kind: ConfigMap
    metadata:
      name: internal-feature-states.csi.vsphere.vmware.com
      namespace: kube-system
kind: ConfigMap
metadata:
  name: internal-feature-states.csi.vsphere.vmware.com
  namespace: {{.eksaSystemNamespace}}
