apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixCluster
metadata:
  name: "{{.clusterName}}"
  namespace: "{{.eksaSystemNamespace}}"
spec:
  prismCentral:
    address: "{{.nutanixEndpoint}}"
    port: {{.nutanixPort}}
    insecure: true
    credentialRef:
      name: "{{.clusterName}}"
      kind: Secret
  controlPlaneEndpoint:
    host: "{{.controlPlaneEndpointIp}}"
    port: 6443
---
apiVersion: v1
kind: Secret
metadata:
  name: "{{.clusterName}}"
  namespace: "{{.eksaSystemNamespace}}"
stringData:
  NUTANIX_PASSWORD: "{{.nutanixPassword}}"
  NUTANIX_USER: "{{.nutanixUser}}"
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: "{{.clusterName}}"
  name: "{{.clusterName}}"
  namespace: "{{.eksaSystemNamespace}}"
spec:
  clusterNetwork:
    services:
      cidrBlocks: {{.serviceCidrs}}
    pods:
      cidrBlocks: {{.podCidrs}}
    serviceDomain: "cluster.local"
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: "{{.clusterName}}"
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: NutanixCluster
    name: "{{.clusterName}}"
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: "{{.clusterName}}"
  namespace: "{{.eksaSystemNamespace}}"
spec:
  replicas: {{.controlPlaneReplicas}}
  version: "{{.kubernetesVersion }}"
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: NutanixMachineTemplate
      name: "{{.clusterName}}-mt-0"
  kubeadmConfigSpec:
    clusterConfiguration:
      imageRepository: "{{.kubernetesRepository}}"
      apiServer:
        certSANs:
          - localhost
          - 127.0.0.1
          - 0.0.0.0
      controllerManager:
        extraArgs:
          enable-hostpath-provisioner: "true"
      dns:
        imageRepository: {{.corednsRepository}}
        imageTag: {{.corednsVersion}}
      etcd:
{{- if .externalEtcd }}
        external:
          endpoints: []
          caFile: "/etc/kubernetes/pki/etcd/ca.crt"
          certFile: "/etc/kubernetes/pki/apiserver-etcd-client.crt"
          keyFile: "/etc/kubernetes/pki/apiserver-etcd-client.key"
{{- else }}
        local:
          imageRepository: {{.etcdRepository}}
          imageTag: {{.etcdImageTag}}
{{- end }}
    files:
      - content: |
          apiVersion: v1
          kind: Pod
          metadata:
            creationTimestamp: null
            name: kube-vip
            namespace: kube-system
          spec:
            containers:
              - name: kube-vip
                image: {{.kubeVipImage}}
                imagePullPolicy: IfNotPresent
                args:
                  - manager
                env:
                  - name: vip_arp
                    value: "true"
                  - name: address
                    value: "{{.controlPlaneEndpointIp}}"
                  - name: port
                    value: "6443"
                  - name: vip_cidr
                    value: "32"
                  - name: cp_enable
                    value: "true"
                  - name: cp_namespace
                    value: kube-system
                  - name: vip_ddns
                    value: "false"
                  - name: vip_leaderelection
                    value: "true"
                  - name: vip_leaseduration
                    value: "15"
                  - name: vip_renewdeadline
                    value: "10"
                  - name: vip_retryperiod
                    value: "2"
                securityContext:
                  capabilities:
                    add:
                      - NET_ADMIN
                      - SYS_TIME
                      - NET_RAW
                volumeMounts:
                  - mountPath: /etc/kubernetes/admin.conf
                    name: kubeconfig
                resources: {}
            hostNetwork: true
            hostAliases:
              - hostnames:
                  - kubernetes
                ip: 127.0.0.1
            volumes:
              - name: kubeconfig
                hostPath:
                  type: FileOrCreate
                  path: /etc/kubernetes/admin.conf
          status: {}
        owner: root:root
        path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          # We have to pin the cgroupDriver to cgroupfs as kubeadm >=1.21 defaults to systemd
          # kind will implement systemd support in: https://github.com/kubernetes-sigs/kind/issues/1726
          #cgroup-driver: cgroupfs
          eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%
    users:
      - name: "{{.controlPlaneSshUsername }}"
        lockPassword: false
        sudo: ALL=(ALL) NOPASSWD:ALL
        sshAuthorizedKeys:
          - "{{.controlPlaneSshAuthorizedKey}}"
    preKubeadmCommands:
      - echo "before kubeadm call" > /var/log/prekubeadm.log
    postKubeadmCommands:
      - echo export KUBECONFIG=/etc/kubernetes/admin.conf >> /root/.bashrc
      - echo "after kubeadm call" > /var/log/postkubeadm.log
    useExperimentalRetryJoin: true
    verbosity: 10

---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: "{{.clusterName}}-kcfg-0"
  namespace: "{{.eksaSystemNamespace}}"
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            # We have to pin the cgroupDriver to cgroupfs as kubeadm >=1.21 defaults to systemd
            # kind will implement systemd support in: https://github.com/kubernetes-sigs/kind/issues/1726
            #cgroup-driver: cgroupfs
            eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%
      users:
        - name: "{{ .controlPlaneSshUsername }}"
          lockPassword: false
          sudo: ALL=(ALL) NOPASSWD:ALL
          sshAuthorizedKeys:
            - "{{.controlPlaneSshAuthorizedKey}}"
      preKubeadmCommands:
        - echo "before kubeadm call" > /var/log/prekubeadm.log
      postKubeadmCommands:
        - echo "after kubeadm call" > /var/log/postkubeadm.log
      verbosity: 10
      #useExperimentalRetryJoin: true